# PropertyEval
A repository of property-based tests for thorough benchmarking of LLM code generation.

## Property-based tests
The `/tests` directory contains directories labelled from `0` to `163`, each of which contains a `strategy.py` file. This file contains the hypothesis strategy for the corresponding problem from the HumanEval dataset. `__init__.py` files have been placed in each directory to allow for importing of the tests as modules. The strategies are available as the `strategy` attribute of these `strategy` modules. Usage of the strategies is as follows.

```python
from hypothesis import given, strategies

@given(strategies.tuples(*st))
def test_property(args):
    # call functions as f(*args)
    # for example, assert f(*args) == ground_truth(*args)
    # ...
```

Here, `st` is the imported strategy. One way to do this is using the `importlib` module.

```python
import importlib

st_module = importlib.import_module(f"test.{humaneval_id}.strategy")
st = st_module.strategy
```

## Evaluation
The `/models` directory contains results from evaluating code samples from 14 models (10 model types) and 5 temperature settings, provided with [EvalPlus v0.1.0 ](https://github.com/evalplus/evalplus/releases/tag/v0.1.0). `/models/list.txt` contains the complete list of these 84 model-size-temperature combinations. These directories do not contain the code samples, but only the `eval_results.json` file generated by the EvalPlus* script. The results are present in a human-readable format in `evaldata.csv`, which provides the following for every model-size-temperature combination.

1. _pass@k_ for `Base`
2. _pass@k_ for `Base + Extra`
3. _pass@k_ for PropertyEval
4. _pass@k_ for PropertyEval with `Base + Extra` as the base (overlap of _successes_)
5. _pass@k_ for PropertyEval with `Base + Extra` as the base, with failures instead of successes (overlap of _failures_)


### *Fork of EvalPlus

We forked [EvalPlus](https://github.com/evalplus/evalplus) and modified the evaluation script to evaluate code samples with PropertyEval's property-based tests as well, in addition to the `Base` and `Base + Extra` test cases. We further used the same functions for estimating _pass@k_ for PropertyEval's property-based tests. The fork is available as [EvalPlusPro](https://github.com/mrigankpawagi/evalpluspro).
